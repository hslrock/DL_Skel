{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_Transform=transforms.Compose([\n",
    "    transforms.Pad((18,18),fill=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "    \n",
    "                                   ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST(root='MNIST_DATASET/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=MNIST_Transform, # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = MNIST(root='MNIST_DATASET/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=MNIST_Transform, # 텐서로 변환\n",
    "                         download=True)\n",
    "\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(mnist_train, [50000, 10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "valid_dl = torch.utils.data.DataLoader(dataset=val_set,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 32,3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "                \n",
    "            \n",
    "        self.layer4= torch.nn.Sequential(\n",
    "            nn.Conv2d(32                    , 32, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "                    \n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(4 * 4 * 32, 625, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(625, 10, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out=self.layer4(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_=dict()\n",
    "config_[\"lr\"]=0.05\n",
    "config_[\"crit\"]=nn.CrossEntropyLoss()\n",
    "config_[\"optim\"]=optim.Adam(model.parameters(),lr=config_[\"lr\"])\n",
    "config_[\"save_dir\"]=\"models/\"\n",
    "config_[\"epochs\"]=10\n",
    "config_[\"train_log\"]=[]\n",
    "config_[\"valid_log\"]=[]\n",
    "\n",
    "config_[\"accuracy\"]=True\n",
    "config_[\"train_acc_log\"]=[]\n",
    "config_[\"valid_acc_log\"]=[]\n",
    "config_[\"log_interval\"]=200\n",
    "config_[\"device\"]=\"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_skel import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 1\n",
      "Batch 1/781 Loss 2.3028361797332764\n",
      "Batch 1/781 Accuracu 0.09375\n",
      "Batch 257/781 Loss 2.313236713409424\n",
      "Batch 257/781 Accuracu 0.10663910505836575\n",
      "Batch 513/781 Loss 2.2785708904266357\n",
      "Batch 513/781 Accuracu 0.10431895711500974\n",
      "Batch 769/781 Loss 2.330502510070801\n",
      "Batch 769/781 Accuracu 0.10439694408322497\n",
      "Validation_Loss: 2.343019723892212\n",
      "Validation_Acc: 0.078125\n",
      "Epochs : 2\n",
      "Batch 1/781 Loss 2.3283658027648926\n",
      "Batch 1/781 Accuracu 0.171875\n",
      "Batch 257/781 Loss 2.345996618270874\n",
      "Batch 257/781 Accuracu 0.10128891050583658\n",
      "Batch 513/781 Loss 2.355766773223877\n",
      "Batch 513/781 Accuracu 0.10069444444444445\n",
      "Batch 769/781 Loss 2.315953016281128\n",
      "Batch 769/781 Accuracu 0.10143042912873862\n",
      "Validation_Loss: 2.325666904449463\n",
      "Validation_Acc: 0.15625\n",
      "Epochs : 3\n",
      "Batch 1/781 Loss 2.337759256362915\n",
      "Batch 1/781 Accuracu 0.03125\n",
      "Batch 257/781 Loss 2.3354859352111816\n",
      "Batch 257/781 Accuracu 0.09970817120622569\n",
      "Batch 513/781 Loss 2.314343214035034\n",
      "Batch 513/781 Accuracu 0.0990801656920078\n",
      "Batch 769/781 Loss 2.2745628356933594\n",
      "Batch 769/781 Accuracu 0.09909379063719116\n",
      "Validation_Loss: 2.290846347808838\n",
      "Validation_Acc: 0.140625\n",
      "Epochs : 4\n",
      "Batch 1/781 Loss 2.3094046115875244\n",
      "Batch 1/781 Accuracu 0.078125\n",
      "Batch 257/781 Loss 2.2920045852661133\n",
      "Batch 257/781 Accuracu 0.10147130350194553\n",
      "Batch 513/781 Loss 2.3704519271850586\n",
      "Batch 513/781 Accuracu 0.09944566276803118\n",
      "Batch 769/781 Loss 2.3123435974121094\n",
      "Batch 769/781 Accuracu 0.10015035760728218\n",
      "Validation_Loss: 2.291931390762329\n",
      "Validation_Acc: 0.109375\n",
      "Epochs : 5\n",
      "Batch 1/781 Loss 2.312683582305908\n",
      "Batch 1/781 Accuracu 0.140625\n",
      "Batch 257/781 Loss 2.3289809226989746\n",
      "Batch 257/781 Accuracu 0.10396400778210117\n",
      "Batch 513/781 Loss 2.39434552192688\n",
      "Batch 513/781 Accuracu 0.10127314814814815\n",
      "Batch 769/781 Loss 2.290800094604492\n",
      "Batch 769/781 Accuracu 0.10010972041612484\n",
      "Validation_Loss: 2.3077943325042725\n",
      "Validation_Acc: 0.15625\n",
      "Epochs : 6\n",
      "Batch 1/781 Loss 2.3363964557647705\n",
      "Batch 1/781 Accuracu 0.109375\n",
      "Batch 257/781 Loss 2.3471944332122803\n",
      "Batch 257/781 Accuracu 0.10378161478599222\n",
      "Batch 513/781 Loss 2.3495917320251465\n",
      "Batch 513/781 Accuracu 0.1032833820662768\n",
      "Batch 769/781 Loss 2.3111066818237305\n",
      "Batch 769/781 Accuracu 0.10362483745123537\n",
      "Validation_Loss: 2.3243911266326904\n",
      "Validation_Acc: 0.109375\n",
      "Epochs : 7\n",
      "Batch 1/781 Loss 2.3308403491973877\n",
      "Batch 1/781 Accuracu 0.203125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8a108e0e3dac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfig_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\DL_Skel\\train_skel.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config, train_dl, valid_dl, model)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mtotal\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m#Update Parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config_,model=train(config_,train_dl,valid_dl,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 7, 9, 7, 9, 8, 3, 5, 8, 5, 1, 3, 5, 0, 9, 7, 0, 0, 6, 2, 6, 2,\n",
       "        4, 2, 1, 7, 8, 2, 6, 0, 5, 3, 7, 2, 9, 0, 2, 4, 8, 7, 7, 6, 0, 7, 9, 8,\n",
       "        1, 9, 5, 1, 6, 3, 6, 9, 8, 0, 0, 0, 0, 1, 7, 7])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
